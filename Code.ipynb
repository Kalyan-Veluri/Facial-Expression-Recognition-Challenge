{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"update.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNLsIdWMGe9t9Ia02oXh2il"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"KU1iW8gbtHoK"},"source":["#importing all the libs\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn import preprocessing\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier, export_graphviz\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import PredefinedSplit\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n","from keras.models import Model, Sequential\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"opVSvT0BtLpm"},"source":["# Reading CSV and naming columns\n","data= pd.read_csv(\"icml_face_data.csv\")\n","data.rename(columns= {' pixels':'pixels',' Usage':'Usage' }, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rkzXoJ1MtNDE"},"source":["print(\"size of data\")\n","len(data)\n","# displaying the length of file"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nTPfgyIctOc8"},"source":["# Dictionary to encode the emotions into numbers\n","emotion_map = {0: 'Angry', 1: 'Digust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n","emotion_counts = data['emotion'].value_counts(sort=False).reset_index()\n","emotion_counts.columns = ['emotion', 'number']\n","emotion_counts['emotion'] = emotion_counts['emotion'].map(emotion_map)\n","emotion_counts"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IM8WMM7NtRDc"},"source":["# plotting data distribution for various emotion images\n","plt.figure(figsize=(6,4))\n","sns.barplot(emotion_counts.emotion, emotion_counts.number)\n","plt.title('Class distribution')\n","plt.ylabel('Number', fontsize=12)\n","plt.xlabel('Emotions', fontsize=12)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G2bzaEDytTCG"},"source":["# plotting sample images for various emotions in gray scale and scaling them to size\n","fig = plt.figure(1, (14, 14))\n","\n","k = 0\n","for label in sorted(data.emotion.unique()):\n","    for j in range(1):\n","        px = data[data.emotion==label].pixels.iloc[k]\n","        px = np.array(px.split(' ')).reshape(48, 48).astype('float32')\n","\n","        k += 1\n","        ax = plt.subplot(7, 7, k)\n","        ax.imshow(px , cmap='gray')\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        ax.set_title(emotion_map[label])\n","        plt.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MsLxFGS3tUAu"},"source":["# getting image pixels into a dataframe for giving it as input to our models\n","pixels_df=  pd.DataFrame(data['pixels'].str.split(' ', expand=True))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tENNBUv9tVZd"},"source":["# converting the above read image pixel values to numeric values by replacing missing pixels(NaN) with 0's\n","print(\"converting to numeric\")\n","pixels_df= pixels_df.apply(pd.to_numeric, errors='coerce').replace(np.nan,0)\n","pixels_df= pixels_df/255\n","print(\"conversion to numeric is done\")\n","final_df= pd.concat([data[['emotion', 'Usage']], pixels_df], axis=1)\n","print(final_df.head())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0odKEZAVtWll"},"source":["#####create train test and validation data sets\n","lab_enc = preprocessing.LabelEncoder()\n","final_df['emotion'] = lab_enc.fit_transform(final_df['emotion'])\n","##\n","X= final_df.drop(['emotion','Usage'], axis=1)\n","Y= final_df['emotion']\n","###\n","x_train,x_test, y_train, y_test= train_test_split(X,Y, test_size=0.15, random_state=1)\n","x_train,x_val, y_train, y_val= train_test_split(x_train,y_train, test_size=0.18, random_state=1)\n","\n","(y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3YAIqiRvtYLt"},"source":["# Training and Predicting using support vector machine using polynomial kernel\n","# average = 'micro' means\n","\"\"\"Micro-averaging is used when a problem has 2 or more labels that can be true, \n","   for example, in our tutorial Build your own music critic. \n","   Micro-averaging F1-score is performed by first calculating the sum of all true positives, false positives, \n","   and false negatives over all the labels.\"\"\"\n","f1_valid = []\n","f1_test = []\n","degree= [2,5,10,20]\n","C= [0.1,1,10,100,1000]\n","gamma= [0.0001,0.001,0.01,1,1.5]\n","valid = []\n","test_data = []\n","best_f1_score=0\n","for d in degree:\n","  for c in C:\n","    for g in gamma:\n","      model= SVC(C=c,gamma=g, degree=d, kernel= 'poly')\n","      print(\"fit the model\")\n","      model.fit(x_train,y_train) \n","      y_pred= model.predict(x_val)\n","      f1_score_val= metrics.f1_score(y_val, y_pred, average='micro')\n","      valid.append(f1_score_val)\n","      y_pred_test= model.predict(x_test)\n","      f1_score_test= metrics.f1_score(y_test, y_pred_test, average='micro')\n","      test_data.append(f1_score_test)\n","      if(f1_score_val>best_f1_score):\n","        best_f1_score= f1_score_val\n","        f1_score_on_test_data= f1_score_test\n","        best_param= {'C':c, 'degree':d, 'gamma':g}\n","###print best f score and best params\n","print('best parameters :',best_param)\n","print('best f1 score :',best_f1_score)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pGq9VXslto3W"},"source":["# printing f1 scores for test and validation data\n","print(\"Best parameters :\", best_param)\n","print(\"f1 score on validation data set :\", f1_score_val)\n","print(\"f1 score on test data set :\", f1_score_test)\n","\n","f1_valid.append(f1_score_val)\n","f1_test.append(f1_score_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_S3jxMqetvk9"},"source":["plt.plot(valid, label='Validation')\n","plt.plot(test_data, label=\"Test\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Z9CDjWNt-5X"},"source":["# Training and Predicting using support vector machine using rbf kernel\n","degree= [2,5,10,20]\n","C= [0.1,1,10,100,1000]\n","gamma= [0.0001,0.001,0.01,1,1.5]\n","best_f1_score=0\n","valid = []\n","test_data = []\n","# for d in degree:\n","for c in C:\n","  for g in gamma:\n","    model= SVC(C=c,gamma=g, kernel= 'rbf')\n","    print(\"fit the model\")\n","    model.fit(x_train,y_train)\n","    # print(\"Best parameters :\", model.best_params_)\n","    ###predict on test dataset \n","    y_pred= model.predict(x_val)\n","    f1_score_val= metrics.f1_score(y_val, y_pred, average='micro')\n","    valid.append(f1_score_val)\n","    # print(y_pred_test)\n","    y_pred_test= model.predict(x_test)\n","    f1_score_test= metrics.f1_score(y_test, y_pred_test, average='micro')\n","    test_data.append(f1_score_test)\n","    # print(\"f score :\", f1_score(y_val, y_pred))\n","    if(f1_score_val>best_f1_score):\n","      best_f1_score= f1_score_val\n","      f1_score_on_test_data= f1_score_test\n","      best_param= {'C':c, 'gamma':g}\n","      print('best parameters :',best_param)\n","      print('best f1 score :',best_f1_score)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vn4zv5wTuR82"},"source":["# printing results for svm with rbf kernel\n","print(\"Best parameters :\", best_param)\n","print(\"f1 score on validation data set :\", f1_score_val)\n","print(\"f1 score on test data set :\", f1_score_test)\n","\n","f1_valid.append(f1_score_val)\n","f1_test.append(f1_score_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZDOb6e9uSh1"},"source":["plt.plot(valid, label='Validation')\n","plt.plot(test_data, label=\"Test\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v7GrgLCruVWt"},"source":["# Training and Predicting using decision trees \n","max_depths=[4,10,20,50]\n","best_f1_score=0\n","for depth in max_depths:\n","\n","  # param_grid={'max_depth':[4,10,20,50]}\n","  model = DecisionTreeClassifier(max_depth=depth, random_state=17)\n","  # model=GridSearchCV(DecisionTreeClassifier(random_state=17),param_grid, n_jobs=-1, verbose=3)\n","  model.fit(x_train,y_train)\n","  ###predict on val and test dataset \n","  y_pred= model.predict(x_val)\n","  y_pred_test= model.predict(x_test)\n","  f1_score_val= metrics.f1_score(y_val, y_pred, average='micro')\n","    # print(y_pred_test)\n","  f1_score_test= metrics.f1_score(y_test, y_pred_test, average='micro')\n","    # print(\"f score :\", f1_score(y_val, y_pred))\n","  if(f1_score_val>best_f1_score):\n","      best_f1_score= f1_score_val\n","      f1_score_on_test_data= f1_score_test\n","      best_param= {'max_depth':depth}\n","##print results\n","print('best parameters :',best_param)\n","print('best f1 score :',best_f1_score)\n","print(\"accuracy score :\", accuracy_score(y_test.astype('int'), y_pred_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wl7jFTm2uYal"},"source":["# printing results for decision tree predictions\n","print(\"Best parameters :\", best_param)\n","print(\"f1 score on validation data set :\", f1_score_val)\n","print(\"f1 score on test data set :\", f1_score_test)\n","\n","f1_valid.append(f1_score_val)\n","f1_test.append(f1_score_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QkPQL_1VuZHc"},"source":["y_train.unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tSMYNoGducWe"},"source":["# Training and Predicting using knn\n","import random\n","all_k= random.sample(range(2,50),25)+random.sample(range(50,1000),75)\n","for k in all_k:\n","  model= KNeighborsClassifier(n_jobs=-1,n_neighbors=k)\n","  model.fit(x_train,y_train)\n","  ###predict on val and test dataset \n","  y_pred= model.predict(x_val)\n","  y_pred_test= model.predict(x_test)\n","  f1_score_val= metrics.f1_score(y_val, y_pred, average='micro')\n","    # print(y_pred_test)\n","  f1_score_test= metrics.f1_score(y_test, y_pred_test, average='micro')\n","    # print(\"f score :\", f1_score(y_val, y_pred))\n","  if(f1_score_val>best_f1_score):\n","      best_f1_score= f1_score_val\n","      f1_score_on_test_data= f1_score_test\n","      best_param= {'k':k}\n","##print best results\n","print('best parameters :',best_param)\n","print('best f1 score :',best_f1_score)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6utNg-XMuevN"},"source":["# printing results for knn model\n","print(\"Best parameters :\", best_param)\n","print(\"f1 score on validation data set :\", f1_score_val)\n","print(\"f1 score on test data set :\", f1_score_test)\n","\n","f1_valid.append(f1_score_val)\n","f1_test.append(f1_score_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qVLeShBquf2G"},"source":["n_group = 4\n","\n","fig, ax = plt.subplots()\n","index = np.arange(n_group)\n","bar_width = 0.35\n","opacity = 0.8\n","\n","r1 = plt.bar(index, f1_valid, bar_width, alpha=opacity, color='b', label='Validation')\n","r2 = plt.bar(index + bar_width, f1_test, bar_width, alpha=opacity, color='g', label='Test')\n","plt.xlabel(\"Model Name\")\n","plt.ylabel(\"F1_score\")\n","plt.title(\"F1_Score for each Model\")\n","plt.xticks(index + bar_width, ('SVM(poly)', \"SVM(rbf)\", \"DT\", \"KNN\"))\n","plt.legend()\n","plt.tight_layout()\n","\n","plt.show()"],"execution_count":null,"outputs":[]}]}